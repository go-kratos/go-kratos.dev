---
title: "æ„å»ºæµå¼æ™ºèƒ½ä½“"
---
<<<<<<< HEAD:src/content/docs/blades/getting-started/runstream.md
# ğŸŒŠ Streaming Calls
Streaming calls (Streaming) are an API communication mode that returns data as it is generated. Unlike the traditional approach of "waiting for the complete response before returning," streaming interfaces send data in chunks (chunks) to the client in real-time as the server generates content, allowing the client to process and display it immediately.

    Characteristics: Low perceived latency, memory-friendly, real-time feedback.
    Suitable for: Chatbots, code completion, real-time translation, pre-processing for speech synthesis, and other scenarios that require high "immediacy."
=======
# ğŸŒŠæµå¼è°ƒç”¨
æµå¼è°ƒç”¨ï¼ˆStreamingï¼‰æ˜¯ä¸€ç§è¾¹ç”Ÿæˆã€è¾¹è¿”å›çš„ API é€šä¿¡æ¨¡å¼ã€‚ä¸ä¼ ç»Ÿâ€œç­‰å¾…å®Œæ•´å“åº”åå†è¿”å›â€çš„æ–¹å¼ä¸åŒï¼Œæµå¼æ¥å£åœ¨æœåŠ¡ç«¯ç”Ÿæˆå†…å®¹çš„è¿‡ç¨‹ä¸­ï¼Œå®æ—¶å°†æ•°æ®åˆ†å—ï¼ˆchunkï¼‰å‘é€ç»™å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯å¯å³æ—¶å¤„ç†å’Œå±•ç¤ºã€‚

    ç‰¹ç‚¹ï¼šä½å»¶è¿Ÿæ„ŸçŸ¥ã€å†…å­˜å‹å¥½ã€å®æ—¶åé¦ˆã€‚
    å¯ç”¨äºï¼šèŠå¤©æœºå™¨äººã€ä»£ç è¡¥å…¨ã€å®æ—¶ç¿»è¯‘ã€è¯­éŸ³åˆæˆå‰å¤„ç†ç­‰ï¼Œå¯¹â€œå³æ—¶æ€§â€è¦æ±‚é«˜çš„åœºæ™¯ã€‚
>>>>>>> c3e0facabaf1dbafee93d281abbd6f78295206db:src/content/docs/zh-cn/blades/get-started/runstream.md

## ğŸš€ä»£ç ç¤ºä¾‹

### å‰ç½®æ¡ä»¶
    1. å®‰è£…Bladesï¼š`go get github.com/go-kratos/blades`
    2. é…ç½®æ¨¡å‹æä¾›è€…ï¼ˆå¦‚OpenAIï¼‰ï¼šè®¾ç½®ç¯å¢ƒå˜é‡`OPENAI_API_KEY`å’Œ`OPENAI_BASE_URL`

```Go
package main

import (
    "context"
    "log"
    "os"
    
    "github.com/go-kratos/blades"
    "github.com/go-kratos/blades/contrib/openai"
)

func main() {
    // Set Environment Variables for OpenAI
    provider := openai.NewChatProvider()
    agent := blades.NewAgent(
    	"Stream Agent",
    	blades.WithProvider(provider),
    	blades.WithModel("deepseek-chat"),
    )
    params := map[string]any{
    	"topic":    "Predict champion of S15",
    	"audience": "General reader",
    }
    prompt, err := blades.NewPromptTemplate().
    	System("Please summarize {{.topic}} ", params).
    	User("Please answer for {{.audience}}, KT and T1 who is more likely to win the final", params).
    	Build()
    if err != nil {
    	log.Fatal(err)
    }
    stream, err := agent.RunStream(context.Background(), prompt)
    if err != nil {
    	log.Fatal(err)
    }
    for stream.Next() {
    	chunk, err := stream.Current()
        if err != nil {
            log.Fatal(err)
        }
    	log.Println(chunk.Text())
    }
}
```
